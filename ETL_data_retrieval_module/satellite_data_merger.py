#!/usr/bin/env python3
"""
Satellite Data Merger - Standalone Utility
H·ª£p nh·∫•t d·ªØ li·ªáu t·ª´ nhi·ªÅu v·ªá tinh d·ª±a tr√™n dictionary task_ids

Usage:
    python satellite_data_merger.py

Features:
    - Nh·∫≠n dictionary task_ids (satellite_name -> task_id)
    - Gi·∫£i n√©n d·ªØ li·ªáu t·ª´ c√°c ZIP files
    - Nh√≥m files theo datetime/timestamp
    - Merge bands c√πng th·ªùi ƒëi·ªÉm th√†nh multi-band images
    - Xu·∫•t ra folder c√≥ t·ªï ch·ª©c ch·ª©a merged data
"""

import os
import shutil
import tempfile
import zipfile
import rasterio
import numpy as np
import requests
from rasterio.warp import reproject, calculate_default_transform, Resampling
from rasterio.windows import Window
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Tuple, Optional
import re

# Configuration
CLIPPED_OUTPUT_DIR = "ETL_data_retrieval_module/data/"


def extract_datetime_from_filename(filename: str) -> Optional[str]:
    """
    Tr√≠ch xu·∫•t datetime t·ª´ t√™n file c·ªßa c√°c v·ªá tinh kh√°c nhau
    
    Args:
        filename: T√™n file (v√≠ d·ª•: 2m_temperature_era5_20240601_040000Z.tif)
    
    Returns:
        Datetime string ho·∫∑c None n·∫øu kh√¥ng parse ƒë∆∞·ª£c
    """
    # Pattern cho ERA5: variable_era5_YYYYMMDD_HHMMSSZ.tif
    era5_pattern = r'era5_(\d{8})_(\d{6})Z\.tif'
    
    # Pattern cho ERA5 legacy: variable_item_id.tif v·ªõi item_id ch·ª©a datetime
    era5_legacy_pattern = r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})'
    
    # Pattern cho Sentinel-2: S2A_MSIL2A_YYYYMMDDTHHMMSS_...
    s2_pattern = r'S2[AB]_MSIL2A_(\d{8}T\d{6})_'
    
    # Pattern cho Sentinel-1: S1A_IW_GRD_YYYYMMDDTHHMMSS_...
    s1_pattern = r'S1[AB]_\w+_\w+_(\d{8}T\d{6})_'
    
    # Pattern t·ªïng qu√°t cho timestamp
    general_pattern = r'(\d{8}T\d{6}|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})'
    
    # Try ERA5 current format first
    match = re.search(era5_pattern, filename)
    if match:
        date_part = match.group(1)  # YYYYMMDD
        time_part = match.group(2)  # HHMMSS
        try:
            dt = datetime.strptime(f"{date_part}T{time_part}", '%Y%m%dT%H%M%S')
            return dt.isoformat()
        except ValueError:
            pass
    
    # Try other patterns
    patterns = [era5_legacy_pattern, s2_pattern, s1_pattern, general_pattern]
    
    for pattern in patterns:
        match = re.search(pattern, filename)
        if match:
            date_str = match.group(1)
            try:
                # Chu·∫©n h√≥a format datetime
                if 'T' in date_str and len(date_str) == 15:  # YYYYMMDDTHHMMSS
                    dt = datetime.strptime(date_str, '%Y%m%dT%H%M%S')
                    return dt.isoformat()
                elif 'T' in date_str and ':' in date_str:  # ISO format
                    return date_str
            except ValueError:
                continue
    
    print(f"‚ö†Ô∏è  Kh√¥ng th·ªÉ parse datetime t·ª´ filename: {filename}")
    return None


def download_task_data(task_id: str, satellite_name: str, api_base_url: str = "http://localhost:8000") -> str:
    """
    Download d·ªØ li·ªáu task t·ª´ API server b·∫±ng GET request
    
    Args:
        task_id: ID c·ªßa task
        satellite_name: T√™n v·ªá tinh (ƒë·ªÉ x√°c ƒë·ªãnh endpoint)
        api_base_url: Base URL c·ªßa API server
    
    Returns:
        ƒê∆∞·ªùng d·∫´n ƒë·∫øn file ZIP ƒë√£ download
        
    Raises:
        Exception: N·∫øu download th·∫•t b·∫°i
    """
    # X√°c ƒë·ªãnh endpoint download d·ª±a tr√™n satellite name
    if satellite_name.lower() == "era5":
        download_url = f"{api_base_url}/v1/era5_download/{task_id}"
    elif satellite_name.lower().startswith("sentinel"):
        download_url = f"{api_base_url}/v1/s2_download/{task_id}"  # Gi·∫£ ƒë·ªãnh c√≥ endpoint t∆∞∆°ng t·ª±
    else:
        # Generic download endpoint ho·∫∑c fallback
        download_url = f"{api_base_url}/v1/download/{task_id}"
    
    print(f"üì° Downloading {satellite_name} data t·ª´: {download_url}")
    
    try:
        # G·ª≠i GET request ƒë·ªÉ download file
        response = requests.get(download_url, stream=True, timeout=60)
        response.raise_for_status()
        
        # T·∫°o th∆∞ m·ª•c t·∫°m ƒë·ªÉ l∆∞u file ZIP
        download_dir = tempfile.mkdtemp(prefix=f"download_{satellite_name}_")
        zip_filename = f"{task_id}.zip"
        zip_path = os.path.join(download_dir, zip_filename)
        
        # L∆∞u file ZIP
        with open(zip_path, 'wb') as f:
            total_size = 0
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    total_size += len(chunk)
        
        print(f"   ‚úì Downloaded {total_size} bytes to {zip_path}")
        return zip_path
        
    except requests.exceptions.RequestException as e:
        raise Exception(f"L·ªói download {satellite_name} task {task_id}: {e}")
    except Exception as e:
        raise Exception(f"L·ªói l∆∞u file {satellite_name}: {e}")


def extract_task_data(task_id: str, satellite_name: str, temp_dir: str, api_base_url: str = "http://localhost:8000") -> str:
    """
    Download v√† gi·∫£i n√©n d·ªØ li·ªáu t·ª´ API server
    
    Args:
        task_id: ID c·ªßa task
        satellite_name: T√™n v·ªá tinh
        temp_dir: Th∆∞ m·ª•c t·∫°m ƒë·ªÉ gi·∫£i n√©n
        api_base_url: Base URL c·ªßa API server
    
    Returns:
        ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a d·ªØ li·ªáu ƒë√£ gi·∫£i n√©n
    """
    # Download ZIP file t·ª´ API
    zip_path = download_task_data(task_id, satellite_name, api_base_url)
    extract_dir = os.path.join(temp_dir, f"{satellite_name}_{task_id}")
    
    print(f"üìÇ Gi·∫£i n√©n {os.path.basename(zip_path)} v√†o {satellite_name} folder...")
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_dir)
        
        # ƒê·∫øm s·ªë files ƒë√£ gi·∫£i n√©n
        tif_count = sum(1 for root, dirs, files in os.walk(extract_dir) 
                       for file in files if file.endswith('.tif'))
        print(f"   ‚úì ƒê√£ gi·∫£i n√©n {tif_count} TIF files t·ª´ {satellite_name}")
        
        return extract_dir
        
    finally:
        # Cleanup downloaded ZIP file
        if os.path.exists(zip_path):
            os.remove(zip_path)
            # C≈©ng x√≥a download directory n·∫øu r·ªóng
            download_dir = os.path.dirname(zip_path)
            try:
                os.rmdir(download_dir)
            except OSError:
                pass  # Directory kh√¥ng r·ªóng ho·∫∑c ƒë√£ b·ªã x√≥a


def group_files_by_datetime(extract_dirs: Dict[str, str]) -> Dict[str, Dict[str, List[str]]]:
    """
    Nh√≥m c√°c file theo datetime t·ª´ t·∫•t c·∫£ satellites
    
    Args:
        extract_dirs: Dict mapping satellite_name -> extracted_directory_path
    
    Returns:
        Dict mapping datetime -> satellite_name -> list_of_files
    """
    datetime_groups = defaultdict(lambda: defaultdict(list))
    
    print("\nüîç Ph√¢n t√≠ch v√† nh√≥m files theo datetime...")
    
    for satellite_name, extract_dir in extract_dirs.items():
        print(f"   Satellite: {satellite_name}")
        
        # T√¨m t·∫•t c·∫£ .tif files trong th∆∞ m·ª•c ƒë√£ gi·∫£i n√©n
        file_count = 0
        for root, dirs, files in os.walk(extract_dir):
            for file in files:
                if file.endswith('.tif'):
                    file_path = os.path.join(root, file)
                    datetime_str = extract_datetime_from_filename(file)
                    
                    if datetime_str:
                        datetime_groups[datetime_str][satellite_name].append(file_path)
                        file_count += 1
                    else:
                        print(f"     ‚ö†Ô∏è  B·ªè qua {file} - kh√¥ng parse ƒë∆∞·ª£c datetime")
        
        print(f"     ‚úì ƒê√£ ph√¢n lo·∫°i {file_count} files")
    
    print(f"\nüìä T·ªïng k·∫øt: {len(datetime_groups)} datetime groups ƒë∆∞·ª£c t·∫°o")
    return dict(datetime_groups)


def get_common_bounds_and_resolution(file_paths: List[str]) -> Tuple[List[float], float, str]:
    """
    T√≠nh to√°n bounds chung v√† resolution cho danh s√°ch files
    
    Args:
        file_paths: Danh s√°ch ƒë∆∞·ªùng d·∫´n ƒë·∫øn files
    
    Returns:
        Tuple (bounds, resolution, crs) chung
    """
    all_bounds = []
    all_resolutions = []
    all_crs = set()
    
    for file_path in file_paths:
        try:
            with rasterio.open(file_path) as src:
                bounds = src.bounds
                all_bounds.append([bounds.left, bounds.bottom, bounds.right, bounds.top])
                all_resolutions.append(abs(src.transform[0]))  # pixel size
                all_crs.add(src.crs.to_string())
        except Exception as e:
            print(f"‚ö†Ô∏è  L·ªói ƒë·ªçc {file_path}: {e}")
            continue
    
    if not all_bounds:
        raise ValueError("Kh√¥ng c√≥ file n√†o h·ª£p l·ªá ƒë·ªÉ t√≠nh bounds")
    
    # T√≠nh union c·ªßa t·∫•t c·∫£ bounds
    min_x = min(b[0] for b in all_bounds)
    min_y = min(b[1] for b in all_bounds)
    max_x = max(b[2] for b in all_bounds)
    max_y = max(b[3] for b in all_bounds)
    
    common_bounds = [min_x, min_y, max_x, max_y]
    
    # S·ª≠ d·ª•ng resolution th√¥ nh·∫•t (l·ªõn nh·∫•t) ƒë·ªÉ tr√°nh oversample
    common_resolution = max(all_resolutions)
    
    # S·ª≠ d·ª•ng CRS ph·ªï bi·∫øn nh·∫•t ho·∫∑c EPSG:4326 n·∫øu c√≥ nhi·ªÅu CRS
    if len(all_crs) == 1:
        common_crs = all_crs.pop()
    else:
        print(f"üåç Ph√°t hi·ªán nhi·ªÅu CRS: {all_crs}, s·ª≠ d·ª•ng EPSG:4326")
        common_crs = "EPSG:4326"
    
    print(f"üó∫Ô∏è  Common bounds: {[round(x, 6) for x in common_bounds]}")
    print(f"üìè Common resolution: {common_resolution:.6f}¬∞")
    print(f"üåê Common CRS: {common_crs}")
    
    return common_bounds, common_resolution, common_crs


def reproject_to_common_grid(
    file_path: str,
    target_bounds: List[float],
    target_resolution: float,
    target_crs: str
) -> Tuple[np.ndarray, rasterio.transform.Affine, dict]:
    """
    Reproject file v·ªÅ common grid
    
    Args:
        file_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn file input
        target_bounds: Bounds m·ª•c ti√™u [minx, miny, maxx, maxy]
        target_resolution: Resolution m·ª•c ti√™u
        target_crs: CRS m·ª•c ti√™u
    
    Returns:
        Tuple (data_array, transform, profile)
    """
    with rasterio.open(file_path) as src:
        # T√≠nh transform v√† dimensions cho target grid
        minx, miny, maxx, maxy = target_bounds
        target_transform = rasterio.transform.from_bounds(
            minx, miny, maxx, maxy,
            int((maxx - minx) / target_resolution),
            int((maxy - miny) / target_resolution)
        )
        
        target_width = int((maxx - minx) / target_resolution)
        target_height = int((maxy - miny) / target_resolution)
        
        # T·∫°o array ƒë·ªÉ ch·ª©a d·ªØ li·ªáu reprojected
        target_data = np.full((target_height, target_width), src.nodata or -9999, dtype=src.dtypes[0])
        
        # Reproject d·ªØ li·ªáu
        reproject(
            source=rasterio.band(src, 1),
            destination=target_data,
            src_transform=src.transform,
            src_crs=src.crs,
            dst_transform=target_transform,
            dst_crs=target_crs,
            resampling=Resampling.bilinear
        )
        
        # T·∫°o profile cho output
        profile = src.profile.copy()
        profile.update({
            'crs': target_crs,
            'transform': target_transform,
            'width': target_width,
            'height': target_height
        })
        
        return target_data, target_transform, profile


def merge_datetime_bands(
    datetime_files: Dict[str, List[str]],
    target_bounds: List[float],
    target_resolution: float,
    target_crs: str,
    output_dir: str,
    datetime_key: str
) -> str:
    """
    Merge t·∫•t c·∫£ bands t·ª´ c√°c satellites cho m·ªôt datetime c·ª• th·ªÉ
    
    Args:
        datetime_files: Dict mapping satellite_name -> list_of_files cho datetime n√†y
        target_bounds: Bounds m·ª•c ti√™u
        target_resolution: Resolution m·ª•c ti√™u
        target_crs: CRS m·ª•c ti√™u
        output_dir: Th∆∞ m·ª•c output
        datetime_key: Key datetime ƒë·ªÉ ƒë·∫∑t t√™n file
    
    Returns:
        ƒê∆∞·ªùng d·∫´n ƒë·∫øn merged file
    """
    all_bands = []
    band_descriptions = []
    
    print(f"üîÑ Merging datetime: {datetime_key}")
    
    # X·ª≠ l√Ω t·ª´ng satellite
    for satellite_name, files in datetime_files.items():
        print(f"   üì° {satellite_name}: {len(files)} files")
        
        for file_path in files:
            try:
                # Reproject v√† clip file v·ªÅ common grid
                data, transform, profile = reproject_to_common_grid(
                    file_path, target_bounds, target_resolution, target_crs
                )
                
                all_bands.append(data)
                
                # T·∫°o description cho band
                filename = os.path.basename(file_path)
                variable_name = filename.replace('.tif', '').split('_')[0]  # Extract variable name
                band_desc = f"{satellite_name}_{variable_name}"
                band_descriptions.append(band_desc)
                
            except Exception as e:
                print(f"     ‚ùå L·ªói x·ª≠ l√Ω {os.path.basename(file_path)}: {e}")
                continue
    
    if not all_bands:
        raise ValueError(f"Kh√¥ng c√≥ bands n√†o ƒë∆∞·ª£c x·ª≠ l√Ω cho datetime {datetime_key}")
    
    # T·∫°o output filename
    safe_datetime = datetime_key.replace(':', '').replace('-', '').replace('T', '_')
    output_filename = f"merged_{safe_datetime}.tif"
    output_path = os.path.join(output_dir, output_filename)
    
    # C·∫≠p nh·∫≠t profile cho multi-band output
    profile.update({
        'count': len(all_bands),
        'compress': 'lzw'
    })
    
    # L∆∞u multi-band file
    with rasterio.open(output_path, "w", **profile) as dst:
        for i, (band_data, description) in enumerate(zip(all_bands, band_descriptions), 1):
            dst.write(band_data, i)
            dst.set_band_description(i, description)
        
        # Th√™m metadata
        dst.update_tags(
            DATETIME=datetime_key,
            BANDS_COUNT=len(all_bands),
            SATELLITE_SOURCES=','.join(datetime_files.keys()),
            CREATION_TIME=datetime.now().isoformat()
        )
    
    print(f"   ‚úÖ T·∫°o {output_filename} v·ªõi {len(all_bands)} bands")
    return output_path


def merge_satellite_data(
    task_ids: Dict[str, str],
    output_folder: str = "merged_satellite_data",
    target_crs: str = "EPSG:4326",
    api_base_url: str = "http://localhost:8000"
) -> str:
    """
    Main function ƒë·ªÉ merge d·ªØ li·ªáu t·ª´ nhi·ªÅu satellites
    
    Args:
        task_ids: Dict mapping satellite_name -> task_id
        output_folder: T√™n folder output (s·∫Ω t·∫°o trong th∆∞ m·ª•c hi·ªán t·∫°i)
        target_crs: Target CRS cho output
        api_base_url: Base URL c·ªßa API server (m·∫∑c ƒë·ªãnh localhost:8000)
    
    Returns:
        ƒê∆∞·ªùng d·∫´n ƒë·∫øn folder output
        
    Example:
        task_ids = {
            "era5": "12345678-1234-1234-1234-123456789abc",
            "sentinel2": "87654321-4321-4321-4321-cba987654321"
        }
        output_dir = merge_satellite_data(task_ids, "my_merged_data", api_base_url="http://localhost:8000")
    """
    print("üöÄ B·∫Øt ƒë·∫ßu merge satellite data")
    print("=" * 50)
    print(f"üìù Input satellites: {list(task_ids.keys())}")
    print(f"üìÇ Output folder: {output_folder}")
    print(f"üåê Target CRS: {target_crs}")
    print()
    
    # T·∫°o th∆∞ m·ª•c output
    output_dir = os.path.abspath(output_folder)
    os.makedirs(output_dir, exist_ok=True)
    
    # T·∫°o th∆∞ m·ª•c t·∫°m
    temp_dir = tempfile.mkdtemp(prefix="satellite_merger_")
    
    try:
        # 1. Download v√† gi·∫£i n√©n d·ªØ li·ªáu t·ª´ t·∫•t c·∫£ tasks
        print("üîì B∆∞·ªõc 1: Download v√† gi·∫£i n√©n d·ªØ li·ªáu t·ª´ task IDs")
        extract_dirs = {}
        for satellite_name, task_id in task_ids.items():
            try:
                extract_dir = extract_task_data(task_id, satellite_name, temp_dir, api_base_url)
                extract_dirs[satellite_name] = extract_dir
            except Exception as e:
                print(f"‚ùå {e}")
                continue
        
        if not extract_dirs:
            raise ValueError("Kh√¥ng c√≥ task n√†o ƒë∆∞·ª£c gi·∫£i n√©n th√†nh c√¥ng")
        
        # 2. Nh√≥m files theo datetime
        print("\nüîÑ B∆∞·ªõc 2: Nh√≥m files theo datetime")
        datetime_groups = group_files_by_datetime(extract_dirs)
        
        if not datetime_groups:
            raise ValueError("Kh√¥ng t√¨m th·∫•y d·ªØ li·ªáu ƒë·ªÉ merge")
        
        # 3. T√≠nh to√°n common bounds v√† resolution
        print("\nüìê B∆∞·ªõc 3: T√≠nh to√°n common grid")
        all_files = []
        for dt_files in datetime_groups.values():
            for sat_files in dt_files.values():
                all_files.extend(sat_files)
        
        common_bounds, common_resolution, detected_crs = get_common_bounds_and_resolution(all_files)
        target_crs = target_crs or detected_crs
        
        # 4. Merge t·ª´ng datetime group
        print(f"\nüîó B∆∞·ªõc 4: Merge {len(datetime_groups)} datetime groups")
        merged_files = []
        
        for i, (datetime_key, datetime_files) in enumerate(datetime_groups.items(), 1):
            try:
                print(f"\n[{i}/{len(datetime_groups)}]", end=" ")
                merged_file = merge_datetime_bands(
                    datetime_files,
                    common_bounds,
                    common_resolution,
                    target_crs,
                    output_dir,
                    datetime_key
                )
                merged_files.append(merged_file)
            except Exception as e:
                print(f"‚ùå L·ªói merge datetime {datetime_key}: {e}")
                continue
        
        if not merged_files:
            raise ValueError("Kh√¥ng c√≥ file n√†o ƒë∆∞·ª£c merge th√†nh c√¥ng")
        
        # 5. T·∫°o summary file
        summary_path = os.path.join(output_dir, "merge_summary.txt")
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("SATELLITE DATA MERGER SUMMARY\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Merge time: {datetime.now().isoformat()}\n")
            f.write(f"Input satellites: {', '.join(task_ids.keys())}\n")
            f.write(f"Task IDs: {task_ids}\n")
            f.write(f"Target CRS: {target_crs}\n")
            f.write(f"Resolution: {common_resolution:.6f}\n")
            f.write(f"Bounds: {common_bounds}\n")
            f.write(f"Datetime groups processed: {len(datetime_groups)}\n")
            f.write(f"Merged files created: {len(merged_files)}\n\n")
            f.write("MERGED FILES:\n")
            for file_path in merged_files:
                f.write(f"  - {os.path.basename(file_path)}\n")
        
        print(f"\nüéâ Ho√†n th√†nh! ƒê√£ t·∫°o {len(merged_files)} merged files")
        print(f"üìÇ Output folder: {output_dir}")
        print(f"üìÑ Summary: {summary_path}")
        
        return output_dir
        
    finally:
        # Cleanup th∆∞ m·ª•c t·∫°m
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)


def main():
    """
    Example usage
    """
    # Example task IDs - thay th·∫ø b·∫±ng task IDs th·ª±c t·∫ø
    task_ids = {
        "era5": "12345678-1234-1234-1234-123456789abc",
        "sentinel2": "87654321-4321-4321-4321-cba987654321"
        # Th√™m c√°c satellites kh√°c n·∫øu c·∫ßn
    }
    
    try:
        output_dir = merge_satellite_data(
            task_ids=task_ids,
            output_folder="merged_satellite_data",
            target_crs="EPSG:4326",
            api_base_url="http://localhost:8000"
        )
        
        print(f"\n‚úÖ Merge completed successfully!")
        print(f"üìÅ Check output folder: {output_dir}")
        
    except Exception as e:
        print(f"\n‚ùå Error during merge: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())

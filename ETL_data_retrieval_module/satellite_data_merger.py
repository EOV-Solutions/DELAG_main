#!/usr/bin/env python3
"""
Satellite Data Merger - Standalone Utility
Há»£p nháº¥t dá»¯ liá»‡u tá»« nhiá»u vá»‡ tinh dá»±a trÃªn dictionary task_ids

Usage:
    python satellite_data_merger.py

Features:
    - Nháº­n dictionary task_ids (satellite_name -> task_id)
    - Giáº£i nÃ©n dá»¯ liá»‡u tá»« cÃ¡c ZIP files
    - NhÃ³m files theo datetime/timestamp
    - Merge bands cÃ¹ng thá»i Ä‘iá»ƒm thÃ nh multi-band images
    - Xuáº¥t ra folder cÃ³ tá»• chá»©c chá»©a merged data
"""

import os
import shutil
import tempfile
import zipfile
import rasterio
import numpy as np
import requests
from rasterio.warp import reproject, calculate_default_transform, Resampling
from rasterio.windows import Window
from pathlib import Path
from datetime import datetime
from collections import defaultdict
from typing import Dict, List, Tuple, Optional
import re

# Configuration
CLIPPED_OUTPUT_DIR = "ETL_data_retrieval_module/data/"


def extract_datetime_from_filename(filename: str) -> Optional[str]:
    """
    TrÃ­ch xuáº¥t datetime tá»« tÃªn file cá»§a cÃ¡c vá»‡ tinh khÃ¡c nhau
    
    Args:
        filename: TÃªn file (vÃ­ dá»¥: 2m_temperature_era5_20240601_040000Z.tif)
    
    Returns:
        Datetime string hoáº·c None náº¿u khÃ´ng parse Ä‘Æ°á»£c
    """
    # Pattern cho ERA5: variable_era5_YYYYMMDD_HHMMSSZ.tif
    era5_pattern = r'era5_(\d{8})_(\d{6})Z\.tif'
    
    # Pattern cho ERA5 legacy: variable_item_id.tif vá»›i item_id chá»©a datetime
    era5_legacy_pattern = r'(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})'
    
    # Pattern cho Sentinel-2: S2A_MSIL2A_YYYYMMDDTHHMMSS_...
    s2_pattern = r'S2[AB]_MSIL2A_(\d{8}T\d{6})_'
    
    # Pattern cho Sentinel-1: S1A_IW_GRD_YYYYMMDDTHHMMSS_...
    s1_pattern = r'S1[AB]_\w+_\w+_(\d{8}T\d{6})_'
    
    # Pattern tá»•ng quÃ¡t cho timestamp
    general_pattern = r'(\d{8}T\d{6}|\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2})'
    
    # Try ERA5 current format first
    match = re.search(era5_pattern, filename)
    if match:
        date_part = match.group(1)  # YYYYMMDD
        time_part = match.group(2)  # HHMMSS
        try:
            dt = datetime.strptime(f"{date_part}T{time_part}", '%Y%m%dT%H%M%S')
            return dt.isoformat()
        except ValueError:
            pass
    
    # Try other patterns
    patterns = [era5_legacy_pattern, s2_pattern, s1_pattern, general_pattern]
    
    for pattern in patterns:
        match = re.search(pattern, filename)
        if match:
            date_str = match.group(1)
            try:
                # Chuáº©n hÃ³a format datetime
                if 'T' in date_str and len(date_str) == 15:  # YYYYMMDDTHHMMSS
                    dt = datetime.strptime(date_str, '%Y%m%dT%H%M%S')
                    return dt.isoformat()
                elif 'T' in date_str and ':' in date_str:  # ISO format
                    return date_str
            except ValueError:
                continue
    
    print(f"âš ï¸  KhÃ´ng thá»ƒ parse datetime tá»« filename: {filename}")
    return None


def download_task_data(task_id: str, satellite_name: str, api_base_url: str = "http://localhost:8000") -> str:
    """
    Download dá»¯ liá»‡u task tá»« API server báº±ng GET request
    
    Args:
        task_id: ID cá»§a task
        satellite_name: TÃªn vá»‡ tinh (Ä‘á»ƒ xÃ¡c Ä‘á»‹nh endpoint)
        api_base_url: Base URL cá»§a API server
    
    Returns:
        ÄÆ°á»ng dáº«n Ä‘áº¿n file ZIP Ä‘Ã£ download
        
    Raises:
        Exception: Náº¿u download tháº¥t báº¡i
    """
    # XÃ¡c Ä‘á»‹nh endpoint download dá»±a trÃªn satellite name
    if satellite_name.lower() == "era5":
        download_url = f"{api_base_url}/v1/era5_download/{task_id}"
    elif satellite_name.lower().startswith("sentinel"):
        download_url = f"{api_base_url}/v1/s2_download/{task_id}"  # Giáº£ Ä‘á»‹nh cÃ³ endpoint tÆ°Æ¡ng tá»±
    else:
        # Generic download endpoint hoáº·c fallback
        download_url = f"{api_base_url}/v1/download/{task_id}"
    
    print(f"ğŸ“¡ Downloading {satellite_name} data tá»«: {download_url}")
    
    try:
        # Gá»­i GET request Ä‘á»ƒ download file
        response = requests.get(download_url, stream=True, timeout=60)
        response.raise_for_status()
        
        # Táº¡o thÆ° má»¥c táº¡m Ä‘á»ƒ lÆ°u file ZIP
        download_dir = tempfile.mkdtemp(prefix=f"download_{satellite_name}_")
        zip_filename = f"{task_id}.zip"
        zip_path = os.path.join(download_dir, zip_filename)
        
        # LÆ°u file ZIP
        with open(zip_path, 'wb') as f:
            total_size = 0
            for chunk in response.iter_content(chunk_size=8192):
                if chunk:
                    f.write(chunk)
                    total_size += len(chunk)
        
        print(f"   âœ“ Downloaded {total_size} bytes to {zip_path}")
        return zip_path
        
    except requests.exceptions.RequestException as e:
        raise Exception(f"Lá»—i download {satellite_name} task {task_id}: {e}")
    except Exception as e:
        raise Exception(f"Lá»—i lÆ°u file {satellite_name}: {e}")


def extract_task_data(task_id: str, satellite_name: str, temp_dir: str, api_base_url: str = "http://localhost:8000") -> str:
    """
    Download vÃ  giáº£i nÃ©n dá»¯ liá»‡u tá»« API server
    
    Args:
        task_id: ID cá»§a task
        satellite_name: TÃªn vá»‡ tinh
        temp_dir: ThÆ° má»¥c táº¡m Ä‘á»ƒ giáº£i nÃ©n
        api_base_url: Base URL cá»§a API server
    
    Returns:
        ÄÆ°á»ng dáº«n Ä‘áº¿n thÆ° má»¥c chá»©a dá»¯ liá»‡u Ä‘Ã£ giáº£i nÃ©n
    """
    # Download ZIP file tá»« API
    zip_path = download_task_data(task_id, satellite_name, api_base_url)
    extract_dir = os.path.join(temp_dir, f"{satellite_name}_{task_id}")
    
    print(f"ğŸ“‚ Giáº£i nÃ©n {os.path.basename(zip_path)} vÃ o {satellite_name} folder...")
    
    try:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(extract_dir)
        
        # Äáº¿m sá»‘ files Ä‘Ã£ giáº£i nÃ©n
        tif_count = sum(1 for root, dirs, files in os.walk(extract_dir) 
                       for file in files if file.endswith('.tif'))
        print(f"   âœ“ ÄÃ£ giáº£i nÃ©n {tif_count} TIF files tá»« {satellite_name}")
        
        return extract_dir
        
    finally:
        # Cleanup downloaded ZIP file
        if os.path.exists(zip_path):
            os.remove(zip_path)
            # CÅ©ng xÃ³a download directory náº¿u rá»—ng
            download_dir = os.path.dirname(zip_path)
            try:
                os.rmdir(download_dir)
            except OSError:
                pass  # Directory khÃ´ng rá»—ng hoáº·c Ä‘Ã£ bá»‹ xÃ³a


def group_files_by_datetime(extract_dirs: Dict[str, str]) -> Dict[str, Dict[str, List[str]]]:
    """
    NhÃ³m cÃ¡c file theo datetime tá»« táº¥t cáº£ satellites
    
    Args:
        extract_dirs: Dict mapping satellite_name -> extracted_directory_path
    
    Returns:
        Dict mapping datetime -> satellite_name -> list_of_files
    """
    datetime_groups = defaultdict(lambda: defaultdict(list))
    
    print("\nğŸ” PhÃ¢n tÃ­ch vÃ  nhÃ³m files theo datetime...")
    
    for satellite_name, extract_dir in extract_dirs.items():
        print(f"   Satellite: {satellite_name}")
        
        # TÃ¬m táº¥t cáº£ .tif files trong thÆ° má»¥c Ä‘Ã£ giáº£i nÃ©n
        file_count = 0
        for root, dirs, files in os.walk(extract_dir):
            for file in files:
                if file.endswith('.tif'):
                    file_path = os.path.join(root, file)
                    datetime_str = extract_datetime_from_filename(file)
                    
                    if datetime_str:
                        datetime_groups[datetime_str][satellite_name].append(file_path)
                        file_count += 1
                    else:
                        print(f"     âš ï¸  Bá» qua {file} - khÃ´ng parse Ä‘Æ°á»£c datetime")
        
        print(f"     âœ“ ÄÃ£ phÃ¢n loáº¡i {file_count} files")
    
    print(f"\nğŸ“Š Tá»•ng káº¿t: {len(datetime_groups)} datetime groups Ä‘Æ°á»£c táº¡o")
    return dict(datetime_groups)


def get_common_bounds_and_resolution(file_paths: List[str]) -> Tuple[List[float], float, str]:
    """
    TÃ­nh toÃ¡n bounds chung vÃ  resolution cho danh sÃ¡ch files
    
    Args:
        file_paths: Danh sÃ¡ch Ä‘Æ°á»ng dáº«n Ä‘áº¿n files
    
    Returns:
        Tuple (bounds, resolution, crs) chung
    """
    all_bounds = []
    all_resolutions = []
    all_crs = set()
    
    for file_path in file_paths:
        try:
            with rasterio.open(file_path) as src:
                bounds = src.bounds
                all_bounds.append([bounds.left, bounds.bottom, bounds.right, bounds.top])
                all_resolutions.append(abs(src.transform[0]))  # pixel size
                all_crs.add(src.crs.to_string())
        except Exception as e:
            print(f"âš ï¸  Lá»—i Ä‘á»c {file_path}: {e}")
            continue
    
    if not all_bounds:
        raise ValueError("KhÃ´ng cÃ³ file nÃ o há»£p lá»‡ Ä‘á»ƒ tÃ­nh bounds")
    
    # TÃ­nh union cá»§a táº¥t cáº£ bounds
    min_x = min(b[0] for b in all_bounds)
    min_y = min(b[1] for b in all_bounds)
    max_x = max(b[2] for b in all_bounds)
    max_y = max(b[3] for b in all_bounds)
    
    common_bounds = [min_x, min_y, max_x, max_y]
    
    # Sá»­ dá»¥ng resolution thÃ´ nháº¥t (lá»›n nháº¥t) Ä‘á»ƒ trÃ¡nh oversample
    common_resolution = max(all_resolutions)
    
    # Sá»­ dá»¥ng CRS phá»• biáº¿n nháº¥t hoáº·c EPSG:4326 náº¿u cÃ³ nhiá»u CRS
    if len(all_crs) == 1:
        common_crs = all_crs.pop()
    else:
        print(f"ğŸŒ PhÃ¡t hiá»‡n nhiá»u CRS: {all_crs}, sá»­ dá»¥ng EPSG:4326")
        common_crs = "EPSG:4326"
    
    print(f"ğŸ—ºï¸  Common bounds: {[round(x, 6) for x in common_bounds]}")
    print(f"ğŸ“ Common resolution: {common_resolution:.6f}Â°")
    print(f"ğŸŒ Common CRS: {common_crs}")
    
    return common_bounds, common_resolution, common_crs


def reproject_to_common_grid(
    file_path: str,
    target_bounds: List[float],
    target_resolution: float,
    target_crs: str
) -> Tuple[np.ndarray, rasterio.transform.Affine, dict]:
    """
    Reproject file vá» common grid
    
    Args:
        file_path: ÄÆ°á»ng dáº«n Ä‘áº¿n file input
        target_bounds: Bounds má»¥c tiÃªu [minx, miny, maxx, maxy]
        target_resolution: Resolution má»¥c tiÃªu
        target_crs: CRS má»¥c tiÃªu
    
    Returns:
        Tuple (data_array, transform, profile)
    """
    with rasterio.open(file_path) as src:
        # TÃ­nh transform vÃ  dimensions cho target grid
        minx, miny, maxx, maxy = target_bounds
        target_transform = rasterio.transform.from_bounds(
            minx, miny, maxx, maxy,
            int((maxx - minx) / target_resolution),
            int((maxy - miny) / target_resolution)
        )
        
        target_width = int((maxx - minx) / target_resolution)
        target_height = int((maxy - miny) / target_resolution)
        
        # Táº¡o array Ä‘á»ƒ chá»©a dá»¯ liá»‡u reprojected
        target_data = np.full((target_height, target_width), src.nodata or -9999, dtype=src.dtypes[0])
        
        # Reproject dá»¯ liá»‡u
        reproject(
            source=rasterio.band(src, 1),
            destination=target_data,
            src_transform=src.transform,
            src_crs=src.crs,
            dst_transform=target_transform,
            dst_crs=target_crs,
            resampling=Resampling.bilinear
        )
        
        # Táº¡o profile cho output
        profile = src.profile.copy()
        profile.update({
            'crs': target_crs,
            'transform': target_transform,
            'width': target_width,
            'height': target_height
        })
        
        return target_data, target_transform, profile


def merge_datetime_bands(
    datetime_files: Dict[str, List[str]],
    target_bounds: List[float],
    target_resolution: float,
    target_crs: str,
    output_dir: str,
    datetime_key: str
) -> str:
    """
    Merge táº¥t cáº£ bands tá»« cÃ¡c satellites cho má»™t datetime cá»¥ thá»ƒ
    
    Args:
        datetime_files: Dict mapping satellite_name -> list_of_files cho datetime nÃ y
        target_bounds: Bounds má»¥c tiÃªu
        target_resolution: Resolution má»¥c tiÃªu
        target_crs: CRS má»¥c tiÃªu
        output_dir: ThÆ° má»¥c output
        datetime_key: Key datetime Ä‘á»ƒ Ä‘áº·t tÃªn file
    
    Returns:
        ÄÆ°á»ng dáº«n Ä‘áº¿n merged file
    """
    all_bands = []
    band_descriptions = []
    
    print(f"ğŸ”„ Merging datetime: {datetime_key}")
    
    # Xá»­ lÃ½ tá»«ng satellite
    for satellite_name, files in datetime_files.items():
        print(f"   ğŸ“¡ {satellite_name}: {len(files)} files")
        
        for file_path in files:
            try:
                # Reproject vÃ  clip file vá» common grid
                data, transform, profile = reproject_to_common_grid(
                    file_path, target_bounds, target_resolution, target_crs
                )
                
                all_bands.append(data)
                
                # Táº¡o description cho band
                filename = os.path.basename(file_path)
                variable_name = filename.replace('.tif', '').split('_')[0]  # Extract variable name
                band_desc = f"{satellite_name}_{variable_name}"
                band_descriptions.append(band_desc)
                
            except Exception as e:
                print(f"     âŒ Lá»—i xá»­ lÃ½ {os.path.basename(file_path)}: {e}")
                continue
    
    if not all_bands:
        raise ValueError(f"KhÃ´ng cÃ³ bands nÃ o Ä‘Æ°á»£c xá»­ lÃ½ cho datetime {datetime_key}")
    
    # Táº¡o output filename
    safe_datetime = datetime_key.replace(':', '').replace('-', '').replace('T', '_')
    output_filename = f"merged_{safe_datetime}.tif"
    output_path = os.path.join(output_dir, output_filename)
    
    # Cáº­p nháº­t profile cho multi-band output
    profile.update({
        'count': len(all_bands),
        'compress': 'lzw'
    })
    
    # LÆ°u multi-band file
    with rasterio.open(output_path, "w", **profile) as dst:
        for i, (band_data, description) in enumerate(zip(all_bands, band_descriptions), 1):
            dst.write(band_data, i)
            dst.set_band_description(i, description)
        
        # ThÃªm metadata
        dst.update_tags(
            DATETIME=datetime_key,
            BANDS_COUNT=len(all_bands),
            SATELLITE_SOURCES=','.join(datetime_files.keys()),
            CREATION_TIME=datetime.now().isoformat()
        )
    
    print(f"   âœ… Táº¡o {output_filename} vá»›i {len(all_bands)} bands")
    return output_path


def merge_satellite_data(
    task_ids: Dict[str, str],
    output_folder: str = "merged_satellite_data",
    target_crs: str = "EPSG:4326",
    api_base_url: str = "http://localhost:8000"
) -> str:
    """
    Main function Ä‘á»ƒ merge dá»¯ liá»‡u tá»« nhiá»u satellites
    
    Args:
        task_ids: Dict mapping satellite_name -> task_id
        output_folder: TÃªn folder output (sáº½ táº¡o trong thÆ° má»¥c hiá»‡n táº¡i)
        target_crs: Target CRS cho output
        api_base_url: Base URL cá»§a API server (máº·c Ä‘á»‹nh localhost:8000)
    
    Returns:
        ÄÆ°á»ng dáº«n Ä‘áº¿n folder output
        
    Example:
        task_ids = {
            "era5": "12345678-1234-1234-1234-123456789abc",
            "sentinel2": "87654321-4321-4321-4321-cba987654321"
        }
        output_dir = merge_satellite_data(task_ids, "my_merged_data", api_base_url="http://localhost:8000")
    """
    print("ğŸš€ Báº¯t Ä‘áº§u merge satellite data")
    print("=" * 50)
    print(f"ğŸ“ Input satellites: {list(task_ids.keys())}")
    print(f"ğŸ“‚ Output folder: {output_folder}")
    print(f"ğŸŒ Target CRS: {target_crs}")
    print()
    
    # Táº¡o thÆ° má»¥c output
    output_dir = os.path.abspath(output_folder)
    os.makedirs(output_dir, exist_ok=True)
    
    # Táº¡o thÆ° má»¥c táº¡m
    temp_dir = tempfile.mkdtemp(prefix="satellite_merger_")
    
    try:
        # 1. Download vÃ  giáº£i nÃ©n dá»¯ liá»‡u tá»« táº¥t cáº£ tasks
        print("ğŸ”“ BÆ°á»›c 1: Download vÃ  giáº£i nÃ©n dá»¯ liá»‡u tá»« task IDs")
        extract_dirs = {}
        for satellite_name, task_id in task_ids.items():
            try:
                extract_dir = extract_task_data(task_id, satellite_name, temp_dir, api_base_url)
                extract_dirs[satellite_name] = extract_dir
            except Exception as e:
                print(f"âŒ {e}")
                continue
        
        if not extract_dirs:
            raise ValueError("KhÃ´ng cÃ³ task nÃ o Ä‘Æ°á»£c giáº£i nÃ©n thÃ nh cÃ´ng")
        
        # 2. NhÃ³m files theo datetime
        print("\nğŸ”„ BÆ°á»›c 2: NhÃ³m files theo datetime")
        datetime_groups = group_files_by_datetime(extract_dirs)
        
        if not datetime_groups:
            raise ValueError("KhÃ´ng tÃ¬m tháº¥y dá»¯ liá»‡u Ä‘á»ƒ merge")
        
        # 3. TÃ­nh toÃ¡n common bounds vÃ  resolution
        print("\nğŸ“ BÆ°á»›c 3: TÃ­nh toÃ¡n common grid")
        all_files = []
        for dt_files in datetime_groups.values():
            for sat_files in dt_files.values():
                all_files.extend(sat_files)
        
        common_bounds, common_resolution, detected_crs = get_common_bounds_and_resolution(all_files)
        target_crs = target_crs or detected_crs
        
        # 4. Merge tá»«ng datetime group
        print(f"\nğŸ”— BÆ°á»›c 4: Merge {len(datetime_groups)} datetime groups")
        merged_files = []
        
        for i, (datetime_key, datetime_files) in enumerate(datetime_groups.items(), 1):
            try:
                print(f"\n[{i}/{len(datetime_groups)}]", end=" ")
                merged_file = merge_datetime_bands(
                    datetime_files,
                    common_bounds,
                    common_resolution,
                    target_crs,
                    output_dir,
                    datetime_key
                )
                merged_files.append(merged_file)
            except Exception as e:
                print(f"âŒ Lá»—i merge datetime {datetime_key}: {e}")
                continue
        
        if not merged_files:
            raise ValueError("KhÃ´ng cÃ³ file nÃ o Ä‘Æ°á»£c merge thÃ nh cÃ´ng")
        
        # 5. Táº¡o summary file
        summary_path = os.path.join(output_dir, "merge_summary.txt")
        with open(summary_path, 'w', encoding='utf-8') as f:
            f.write("SATELLITE DATA MERGER SUMMARY\n")
            f.write("=" * 50 + "\n\n")
            f.write(f"Merge time: {datetime.now().isoformat()}\n")
            f.write(f"Input satellites: {', '.join(task_ids.keys())}\n")
            f.write(f"Task IDs: {task_ids}\n")
            f.write(f"Target CRS: {target_crs}\n")
            f.write(f"Resolution: {common_resolution:.6f}\n")
            f.write(f"Bounds: {common_bounds}\n")
            f.write(f"Datetime groups processed: {len(datetime_groups)}\n")
            f.write(f"Merged files created: {len(merged_files)}\n\n")
            f.write("MERGED FILES:\n")
            for file_path in merged_files:
                f.write(f"  - {os.path.basename(file_path)}\n")
        
        print(f"\nğŸ‰ HoÃ n thÃ nh! ÄÃ£ táº¡o {len(merged_files)} merged files")
        print(f"ğŸ“‚ Output folder: {output_dir}")
        print(f"ğŸ“„ Summary: {summary_path}")
        
        return output_dir
        
    finally:
        # Cleanup thÆ° má»¥c táº¡m
        if os.path.exists(temp_dir):
            shutil.rmtree(temp_dir)


def main():
    """
    Example usage
    """
    # Example task IDs - thay tháº¿ báº±ng task IDs thá»±c táº¿
    task_ids = {
        "era5": "12345678-1234-1234-1234-123456789abc",
        "sentinel2": "87654321-4321-4321-4321-cba987654321"
        # ThÃªm cÃ¡c satellites khÃ¡c náº¿u cáº§n
    }
    
    try:
        output_dir = merge_satellite_data(
            task_ids=task_ids,
            output_folder="merged_satellite_data",
            target_crs="EPSG:4326",
            api_base_url="http://localhost:8000"
        )
        
        print(f"\nâœ… Merge completed successfully!")
        print(f"ğŸ“ Check output folder: {output_dir}")
        
    except Exception as e:
        print(f"\nâŒ Error during merge: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    import sys
    sys.exit(main())
